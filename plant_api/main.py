from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import onnxruntime as ort
from PIL import Image
import numpy as np
import json
import io
from pathlib import Path
import uvicorn
from contextlib import asynccontextmanager

# ================================
# ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏
# ================================
BASE_DIR = Path(__file__).parent
MODEL_PATH = BASE_DIR / "plant_disease_model.onnx"
CLASSES_PATH = BASE_DIR / "class_names.json"

# ================================
# üîÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
# ================================
def preprocess_image(file_bytes: bytes) -> np.ndarray:
    """
    RU: –ü—Ä–∏–≤–æ–¥–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫ [1, 3, 224, 224], –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
    EN: Convert image to [1, 3, 224, 224], normalize like in training
    """
    try:
        image = Image.open(io.BytesIO(file_bytes)).convert("RGB")
    except Exception as e:
        raise ValueError(f"cannot open image: {e}")

    # RU: LANCZOS –¥–∞—ë—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–µ—Å–∞–π–∑; –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ—Ç –∂–µ –º–µ—Ç–æ–¥
    # EN: LANCZOS gives high-quality resize; match training pipeline if possible
    image = image.resize((224, 224), Image.LANCZOS)

    x = np.asarray(image, dtype=np.float32) / 255.0
    # RU: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, –∫–∞–∫ —É –≤–∞—Å –±—ã–ª–æ; –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ ImageNet mean/std
    # EN: Keep your (x-0.5)/0.5 normalization; swap to ImageNet mean/std if you trained that way
    x = (x - 0.5) / 0.5

    # RU: HWC -> CHW -> NCHW
    # EN: HWC -> CHW -> NCHW
    x = np.transpose(x, (2, 0, 1))
    x = np.expand_dims(x, axis=0)
    return x  # (1, 3, 224, 224)


def softmax(x: np.ndarray, axis: int = -1) -> np.ndarray:
    """
    RU: –ß–∏—Å–ª–µ–Ω–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π softmax
    EN: Numerically stable softmax
    """
    x_max = np.max(x, axis=axis, keepdims=True)
    e = np.exp(x - x_max)
    s = np.sum(e, axis=axis, keepdims=True)
    # RU: –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –Ω–æ–ª—å
    # EN: Avoid division by zero
    s = np.where(s == 0, 1.0, s)
    return e / s

# ================================
# üå± Lifespan: –∑–∞–≥—Ä—É–∑–∫–∞/–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
# üå± Lifespan: load/release resources
# ================================
@asynccontextmanager
async def lifespan(app: FastAPI):
    # RU: –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    # EN: Load artifacts on startup
    if not MODEL_PATH.exists():
        raise RuntimeError(f"‚ùå Model file not found: {MODEL_PATH}")
    if not CLASSES_PATH.exists():
        raise RuntimeError(f"‚ùå class_names.json not found: {CLASSES_PATH}")

    with open(CLASSES_PATH, "r", encoding="utf-8") as f:
        class_names = json.load(f)
        if not isinstance(class_names, list) or not all(isinstance(c, str) for c in class_names):
            raise RuntimeError("class_names.json must be a JSON array of strings")
        app.state.class_names = class_names

    # RU: –Ø–≤–Ω–æ –≤—ã–±–∏—Ä–∞–µ–º CPU, –Ω–æ –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
    # EN: Use CPU provider explicitly; you may probe available providers if needed
    try:
        app.state.session = ort.InferenceSession(
            str(MODEL_PATH),
            providers=["CPUExecutionProvider"]
        )
    except Exception as e:
        raise RuntimeError(f"Failed to load ONNX model: {e}")

    print(f"‚úÖ Model loaded with {len(app.state.class_names)} classes.")

    try:
        yield
    finally:
        # RU: –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        # EN: Cleanup on shutdown (optional)
        app.state.session = None

# ================================
# üåê –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI —Å lifespan
# ================================
app = FastAPI(title="Plant Disease Detector API", lifespan=lifespan)

# CORS (–Ω–∞ –ø—Ä–æ–¥–µ –ª—É—á—à–µ —É–∫–∞–∑–∞—Ç—å –¥–æ–º–µ–Ω —Ñ—Ä–æ–Ω—Ç–∞)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # e.g., ["https://your-frontend.app"]
    allow_credentials=False,  # RU: –ù–µ–ª—å–∑—è True —Å allow_origins=["*"]
    allow_methods=["*"],
    allow_headers=["*"],
)

# ================================
# üìå Healthcheck
# ================================
@app.get("/health")
def health():
    return {"status": "ok", "classes": len(getattr(app.state, "class_names", []))}

# ================================
# üìå –ú–æ–¥–µ–ª—å –æ—Ç–≤–µ—Ç–∞
# ================================
class DiseasePrediction(BaseModel):
    disease_class: str
    confidence: float

class PredictResponse(BaseModel):
    disease_class: str
    confidence: float
    top_predicts: list[DiseasePrediction]

# ================================
# üìå –≠–Ω–¥–ø–æ–∏–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
# ================================
@app.post("/predict", response_model=PredictResponse)
async def predict(file: UploadFile = File(...)):
    session = getattr(app.state, "session", None)
    class_names = getattr(app.state, "class_names", None)

    if session is None or not class_names:
        raise HTTPException(status_code=503, detail="Model not loaded")

    # RU: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ —Ç–∏–ø—É –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —á–µ—Ä–µ–∑ file.content_type
    # EN: You can validate MIME type via file.content_type
    content = await file.read()
    if not content:
        raise HTTPException(status_code=400, detail="Empty file")

    try:
        inp = preprocess_image(content)  # (1, 3, 224, 224)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Invalid image: {e}")

    try:
        input_name = session.get_inputs()[0].name
        output = session.run(None, {input_name: inp})[0]  # (1, num_classes)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Inference failed: {e}")

    if output.ndim != 2 or output.shape[0] != 1:
        raise HTTPException(status_code=500, detail=f"Unexpected model output shape: {output.shape}")

    logits = output[0]  # (num_classes,)
    probs = softmax(logits, axis=-1).astype(float)  # ensure JSON‚Äëserializable

    top_idx = int(np.argmax(probs))
    top_conf = float(probs[top_idx])

    # Top‚Äë5 (–∏–ª–∏ –º–µ–Ω—å—à–µ, –µ—Å–ª–∏ –∫–ª–∞—Å—Å–æ–≤ <5)
    k = min(5, len(class_names))
    top_predicts_idx = np.argsort(probs)[::-1][:k]
    top_predicts = [
        {"disease_class": class_names[i], "confidence": float(probs[i])}
        for i in top_predicts_idx
    ]

    return PredictResponse(
        disease_class=class_names[top_idx],
        confidence=top_conf,
        top_predicts=top_predicts,  # ‚úÖ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    )

# ================================
# üîπ –õ–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫
# ================================
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
