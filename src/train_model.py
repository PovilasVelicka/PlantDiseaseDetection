# üß† –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ MobileNetV2 (Transfer Learning)
# üß† Training MobileNetV2 model (Transfer Learning)

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import models
from tqdm import tqdm
from torchvision import datasets, transforms
import os
BASE_DIR = "../content/plant_disease_split"
# ================================
# 2Ô∏è‚É£ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
# 2Ô∏è‚É£ Augmentations
# ================================
train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),                # RU: –ø—Ä–∏–≤–æ–¥–∏–º —Ä–∞–∑–º–µ—Ä / EN: resize
    transforms.RandomHorizontalFlip(),            # RU: —Å–ª—É—á–∞–π–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ / EN: random flip
    transforms.RandomRotation(10),                # RU: —Å–ª—É—á–∞–π–Ω—ã–π –ø–æ–≤–æ—Ä–æ—Ç / EN: rotation
    transforms.ToTensor(),                        # RU: –≤ —Ç–µ–Ω–∑–æ—Ä / EN: to tensor
    transforms.Normalize(mean=[0.5,0.5,0.5],
                         std=[0.5,0.5,0.5])        # RU: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è / EN: normalize
])

val_test_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5,0.5,0.5],
                         std=[0.5,0.5,0.5])
])

# ================================
# 3Ô∏è‚É£ DataLoader
# ================================
train_dataset = datasets.ImageFolder(os.path.join(BASE_DIR, "train"), transform=train_transforms)
val_dataset   = datasets.ImageFolder(os.path.join(BASE_DIR, "val"), transform=val_test_transforms)
test_dataset  = datasets.ImageFolder(os.path.join(BASE_DIR, "test"), transform=val_test_transforms)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)

print(f"üìä –ö–ª–∞—Å—Å—ã / Classes: {train_dataset.classes}")
print(f"üìà –†–∞–∑–º–µ—Ä train: {len(train_dataset)}, val: {len(val_dataset)}, test: {len(test_dataset)}")


# RU: –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
# EN: Select device (GPU if available)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üîπ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ / Using device: {device}")

# RU: –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é MobileNetV2
# EN: Load pretrained MobileNetV2
model = models.mobilenet_v2(pretrained=True)

# RU: –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫—Ä–æ–º–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
# EN: Freeze all layers except classifier
for param in model.features.parameters():
    param.requires_grad = False

# RU: –ó–∞–º–µ–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –ø–æ–¥ –Ω–∞—à–µ —á–∏—Å–ª–æ –∫–ª–∞—Å—Å–æ–≤
# EN: Replace last layer for our number of classes
num_classes = len(train_dataset.classes)
model.classifier[1] = nn.Linear(model.last_channel, num_classes)

model = model.to(device)

# ================================
# Loss –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä / Loss & optimizer
# ================================
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# ================================
# –§—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
# Training function
# ================================
def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5):
    for epoch in range(num_epochs):
        # ---- Training phase ----
        model.train()
        running_loss = 0.0
        running_corrects = 0

        for inputs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} [Train]"):
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            _, preds = torch.max(outputs, 1)
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = running_corrects.double() / len(train_loader.dataset)

        # ---- Validation phase ----
        model.eval()
        val_loss = 0.0
        val_corrects = 0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                _, preds = torch.max(outputs, 1)
                val_loss += loss.item() * inputs.size(0)
                val_corrects += torch.sum(preds == labels.data)

        val_loss /= len(val_loader.dataset)
        val_acc = val_corrects.double() / len(val_loader.dataset)

        print(f"üìÖ Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} | Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}")

    return model

# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5)

# üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
# üíæ Saving trained model

# RU: –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ PyTorch
# EN: Save weights in PyTorch format
torch.save(model.state_dict(), "plant_disease_model.pth")
print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ plant_disease_model.pth")

# RU: –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX –¥–ª—è –¥–µ–ø–ª–æ—è –≤ Azure –∏–ª–∏ –±—Ä–∞—É–∑–µ—Ä
# EN: Export to ONNX for Azure or browser deployment
dummy_input = torch.randn(1, 3, 224, 224, device=device)
torch.onnx.export(
    model,
    dummy_input,
    "plant_disease_model.onnx",
    input_names=["input"],
    output_names=["output"],
    dynamic_axes={"input": {0: "batch_size"}, "output": {0: "batch_size"}}
)
print("‚úÖ –ú–æ–¥–µ–ª—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ plant_disease_model.onnx")